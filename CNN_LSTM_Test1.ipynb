{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T11:34:16.857756Z",
     "start_time": "2019-03-08T11:34:16.720669Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import keras\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn import random_projection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:57:08.893364Z",
     "start_time": "2019-03-08T08:57:07.755443Z"
    }
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(\"data/train.csv\")\n",
    "Test = pd.read_csv(\"data/test.csv\")\n",
    "Valid = pd.read_csv(\"data/valid.csv\")\n",
    "\n",
    "#################################################################\n",
    "Train = Train.iloc[0:10000,:]\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:57:09.041960Z",
     "start_time": "2019-03-08T08:57:09.037542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label\n",
    "Train_y = Train['stars']\n",
    "Test_y = Valid['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:57:09.353842Z",
     "start_time": "2019-03-08T08:57:09.188925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of comments in train is 112.\n",
      "Average word length of comments in test is 111.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of comments in train is {0:.0f}.'.format(np.mean(Train['text'].apply(lambda x: len(x.split())))))\n",
    "print('Average word length of comments in test is {0:.0f}.'.format(np.mean(Test['text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:57:38.902189Z",
     "start_time": "2019-03-08T08:57:09.497976Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
    "full_text = list(Train['text'].values) + list(Test['text'].values)\n",
    "vectorizer.fit(full_text)\n",
    "train_vectorized = vectorizer.transform(Train['text'])\n",
    "test_vectorized = vectorizer.transform(Test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:01:04.344611Z",
     "start_time": "2019-03-07T16:01:00.714855Z"
    }
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer(lower = True, filters='')\n",
    "tk.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:01:09.035401Z",
     "start_time": "2019-03-07T16:01:07.058793Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tokenized = tk.texts_to_sequences(Train['text'])\n",
    "test_tokenized = tk.texts_to_sequences(Test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:15:11.897984Z",
     "start_time": "2019-03-07T16:15:11.683349Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 1\n",
    "x_train_padded_seqs = pad_sequences(train_tokenized, maxlen = max_len)\n",
    "x_test_padded_seqs = pad_sequences(test_tokenized, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T16:24:33.837250Z",
     "start_time": "2019-03-07T16:24:31.407344Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_padded_seqs_split=[]\n",
    "for i in range(x_test_padded_seqs.shape[0]):\n",
    "    split1=np.split(x_test_padded_seqs[i],5)\n",
    "    a=[]\n",
    "    for j in range(5):\n",
    "        s=np.split(split1[j],5)\n",
    "        a.append(s)\n",
    "    x_test_padded_seqs_split.append(a)\n",
    "    \n",
    "x_train_padded_seqs_split=[]\n",
    "for i in range(x_train_padded_seqs.shape[0]):\n",
    "    split1=np.split(x_train_padded_seqs[i],5)\n",
    "    a=[]\n",
    "    for j in range(5):\n",
    "        s=np.split(split1[j],5)\n",
    "        a.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T06:55:26.822509Z",
     "start_time": "2019-03-07T06:55:26.819542Z"
    }
   },
   "source": [
    "embedding_path = \"../crawl-300d-2M.vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T06:55:28.879883Z",
     "start_time": "2019-03-07T06:55:28.875751Z"
    }
   },
   "source": [
    "embed_size = 300\n",
    "max_features = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T06:58:02.662598Z",
     "start_time": "2019-03-07T06:55:43.579291Z"
    }
   },
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
    "\n",
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:57:39.867317Z",
     "start_time": "2019-03-08T08:57:39.854076Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_ohe = ohe.fit_transform(Train_y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:59:34.218036Z",
     "start_time": "2019-03-08T08:59:34.214744Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "embedding_size = 10\n",
    "input_length = 30\n",
    "filters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:22:12.922118Z",
     "start_time": "2019-03-08T09:22:07.292069Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputdict = {}\n",
    "grudict = {}\n",
    "Encoderdict = {}\n",
    "embeddict = {}\n",
    "shapelist = (int(64//64),)\n",
    "\n",
    "inputdict['input1'] = Input(shape=shapelist, dtype='int32')\n",
    "embeddict['embed'] = Embedding(input_dim=input_size, output_dim=embedding_size, input_length=input_length)(inputdict['input1'])\n",
    "grudict['gru1'] = GRU(filters,recurrent_activation='sigmoid',activation=None,return_sequences=False)(embeddict['embed'])\n",
    "grudict['gru1'] =Dropout(0.5)(grudict['gru1'])\n",
    "Encoderdict['Encoder1'] = Model(inputdict['input1'], grudict['gru1'])\n",
    "\n",
    "\n",
    "for i in range(2,10):\n",
    "    \n",
    "    shapelist = (5,) + shapelist\n",
    "    inputname = 'input'+str(i)\n",
    "    Encodernameprev = 'Encoder'+ str(i-1)\n",
    "    Encodername = 'Encoder'+str(i)\n",
    "    embedname = 'embed'+str(i)\n",
    "    gruname = 'gru'+str(i)\n",
    "    \n",
    "    inputdict[inputname] = Input(shape=shapelist, dtype='int32')\n",
    "    embeddict[embedname] = TimeDistributed(Encoderdict[Encodernameprev])(inputdict[inputname])\n",
    "    grudict[gruname] = GRU(filters,recurrent_activation='sigmoid',activation=None,return_sequences=False)(embeddict[embedname])\n",
    "    grudict[gruname] =Dropout(0.5)(grudict[gruname])\n",
    "    Encoderdict[Encodername] = Model(inputdict[inputname],grudict[gruname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:22:13.499272Z",
     "start_time": "2019-03-08T09:22:13.434823Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        (None, 5, 5, 1)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 5, 10)             1360      \n",
      "_________________________________________________________________\n",
      "gru_39 (GRU)                 (None, 10)                630       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 2,045\n",
      "Trainable params: 2,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preds = Dense(5, activation='softmax')(grudict['gru3'])\n",
    "model = Model(inputdict['input3'], preds)\n",
    "\n",
    "# print(Encoder1.summary())\n",
    "# print(Encoder2.summary())\n",
    "print(model.summary())\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:22:32.471536Z",
     "start_time": "2019-03-08T09:22:32.467091Z"
    }
   },
   "outputs": [],
   "source": [
    "savebestmodel = 'SRNN(10).h5'\n",
    "checkpoint = ModelCheckpoint(savebestmodel, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlyStopping=EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:22:32.958600Z",
     "start_time": "2019-03-08T09:22:32.929605Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_40 to have 4 dimensions, but got array with shape (10000, 562328)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4c80366acf4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_40 to have 4 dimensions, but got array with shape (10000, 562328)"
     ]
    }
   ],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(\n",
    "            self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='weighted')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='weighted')\n",
    "        _val_precision = precision_score(\n",
    "            val_targ, val_predict, average='weighted')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(' — val_f1: %f — val_precision: %f — val_recall %f' %\n",
    "              (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "\n",
    "callbacks = [checkpoint, metrics, earlyStopping]\n",
    "\n",
    "history = model.fit(train_vectorized, y_ohe,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T09:54:34.254334Z",
     "start_time": "2019-03-08T09:54:34.236846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:01:29.289416Z",
     "start_time": "2019-03-07T14:01:29.277775Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"best_model.hdf5\"\n",
    "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                              save_best_only = True, mode = \"min\")\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "\n",
    "def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(input_dim=input_size, output_dim=embedding_size, input_length=input_length)(inp)\n",
    "    x1 = SpatialDropout1D(dr)(x)\n",
    "\n",
    "    x_gru = Bidirectional(CudnnRNN(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    x_lstm = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(32, kernel_size=3, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(32, kernel_size=2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    \n",
    "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
    "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(Dense(128,activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(Dense(100,activation='relu') (x))\n",
    "    x = Dense(5, activation = \"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 15, validation_split=0.1, \n",
    "                        verbose = 1, callbacks = [check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:46:20.269049Z",
     "start_time": "2019-03-07T15:46:20.264178Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'get_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a028d0e9644b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-b258c0dde9cc>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(lr, lr_d, units, dr)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#     x_gru = Bidirectional(CudnnRNN(units, return_sequences = True))(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, merge_mode, weights, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m                              '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'go_backwards'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'go_backwards'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'get_config'"
     ]
    }
   ],
   "source": [
    "model = build_model(lr = 1e-4, lr_d = 0, units = 128, dr = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T15:46:20.269049Z",
     "start_time": "2019-03-07T15:46:20.264178Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
    "sub['Sentiment'] = predictions\n",
    "sub.to_csv(\"blend.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "9999",
    "lenType": "9999",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "375px",
    "left": "1018px",
    "right": "0px",
    "top": "75px",
    "width": "371px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
